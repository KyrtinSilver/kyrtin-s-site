---
title: "067 - Red Flags"
layout: essay.njk
date: "2023-09-21"
---

Red Flags typically indicating fraud and disinformation in AI and Tech today (95% probability, 5% error margin):

1. "Data-driven"

2. "Guardrails"

3. "Responsible AI"

4. "Foundation Models"

5. "Constitutional AI"

6. "Synthetic Data"

7. "Explainable" (context: narrow AI)

8. "Ethical" (context: narrow AI)

9. "Reasoning/Understanding" (context: narrow AI)

10. "AGI" (context: firms who focus on LLMs, RL, and image generators)

These examples are just from my recent LinkedIn feed, and I routinely block the more obvious Misinformation/Disinformation Brokers like Linas B. and Allie M. Keep in mind, they also cycle through terms, creating new ones to exploit, every few months. This helps to keep people off-balance, allowing the hype to flow and socially engineer more effectively.

One of the more damaging effects of these terms being abused is that the information ecosystem is critically contaminated by that abuse, and misinformation quickly comes to saturate it, pushing sanitary information out of view. That means that the people polluting the information ecosystem are directly responsible for preventing solutions to the problems they claim to solve, or "advocate" for solving.

If someone uses any of these terms, don't take what they have to say at face value. There is a small chance that they're using them accurately and not engaging in fraud, but the base rate probability points in the opposite direction. Popularity is also inversely correlated with credibility, so it pays to be more skeptical of better-known individuals.

Image generated by Bing, because my sense of humor involves making the people waving the most red flags generate the image to describe themselves.