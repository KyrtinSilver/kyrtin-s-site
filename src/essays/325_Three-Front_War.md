---
title: "325 - Three-Front War"
layout: essay.njk
date: "2025-07-03"
---

History has some lessons for us, such as the story of [Orson Welles and the famous “War of the Worlds” broadcast.](https://www.youtube.com/watch?v=BkG70_wa4a8) His motivation, as told by the man himself, was that people shouldn't believe everything communicated through new technology by default, as he observed people doing with the radio in his time. This tendency has since been documented in cognitive bias research.

This lesson hasn't quite sunk in for humanity (as tends to be the case for cognitive biases), because people repeated this mistake with AI. Bad actors even took it a step further to not just mislead people with a broadcast, but to systematically and repeatedly flood them with such disinformation for several years (and counting).

The parallel to what later happened when Pearl Harbor was bombed, and the news wasn't believed, also rings true for the present, as many of the same things that the bad actors of AI promise (but can't deliver) others can and likely will, just not as quickly as those bad actors can make the claim. The predictable consequence is disbelief of the credible, following the discrediting of the rest, further multiplying the damage of AI's numerous bad actors.

Someone recently gave me their insight into a particular series of cognitive biases they observed guiding post-ChatGPT investments in the AI space, something anecdotal (and counter-intuitive), but also highly consistent with our observations, and sufficiently horrifying in its implications. What it boils down to is that investors became categorically biased against the very (and only) thing capable of delivering on the promises being made for AI, instead swallowing the snake oil bait hook, line, and sinker.

This is one specific form of the above case, where the lie is broadcast (continuously and "generatively" in the case of AI), and the credible isn't believed. Trash AI burns in many dumpsters across the domain, and many people seem all too content to burn the house down around them, spreading that flaming trash far and wide.

The pity is that the people in a position to change the situation are also the most likely to take the bait for scams like OpenAI, Anthropic, or their spin-off derivative frauds. Bad actors might have junk for technology, but they can polish bullshit to a mirror sheen, and they do so aiming directly at anyone with a full wallet and decorative head.

Even as physical wars rage across the world, and Cybercrime wages a digital war as the world's third-largest market at >10 trillion USD annually, the information war is destroying all semblance of credibility, trust, and even search-ability. How long can you survive a war on 3 fronts?