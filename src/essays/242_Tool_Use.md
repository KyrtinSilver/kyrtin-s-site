---
title: "242 - Tool Use"
layout: "essay.njk"
date: 2024-11-03
---

“Tool Use” and utilizing information resources like the internet itself are a popular subject in AI/ML and a natural target for companies to orient their product “features” around. Of course, all hype aside, typical AI/ML systems are spectacularly terrible at tool use and information resource utilization in general, and only marginally improved with major investments of engineering time and compute.

Right now the market offers 1,000 terrible attempts at “tool use” and “AI search”, including the EXTREMELY Anthropomorphized PR videos from OpenAI and Anthropic.

The simple fact is that a system that can’t independently generalize to the point of creating new tools for new circumstances also can’t reliably use tools within real-world complexity, at least absent extremely labor-intensive and fragile hand-engineering efforts. This can also be used as a litmus test for “tool use viability”, as the overwhelming majority of attempts to claim “tool use” will fall flat by this measure.

Searching information resources to retrieve useful and/or desired information, potentially summarizing or analyzing it in subsequent steps, fundamentally falls far beyond the capacities of systems like LLMs for similar reasons. However, in addition to all of the problems they have with tool use, they also “bullshit” 100% of the time, even if some fraction of that bullshitting happens to agree with reality at any given point. They have no way of distinguishing fact from fiction, by design.

Lacking any human-like motivational system, and having only the weakest, shallowest, and trivial imitation of human cognitive processes, these systems rely on narrow optimizers, which as the name implies can’t handle real-world complexity. These weak systems of mimicry can be trained on human data, but that only optimizes them to a fuzzy shadow, not to the dynamics of the systems casting that shadow, humans.

At the extreme end of “magical thinking” we have the current “Agentic” collection of buzzwords, where the raw sewage of cognitive biases carefully mixed with snake oil are bottled and sold. This could also be termed the “Anthropomorphism is all you need” crowd, which as noted above has been carefully weaponized by the industry's major bad actors.

If you want viable tool use, you need actual intelligence, with a human-like motivational system, and the cognitive processes of a working cognitive architecture. Fortunately, those aren’t theoretical, they’ve been demonstrated for half a decade. Ironically, nobody was paying "Attention".

