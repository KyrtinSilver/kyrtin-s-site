---
title: "319 - Cognitive Atrophy"
layout: essay.njk
date: "2025-06-27"
---

The AI domain recently became abuzz with the [“Your Brain on ChatGPT”](https://arxiv.org/abs/2506.08872) paper (a name that pairs well with the ["ChatGPT is Bullshit"](https://www.researchgate.net/publication/381278855_ChatGPT_is_bullshit) paper), but as the paper is just over 200 pages long and because I’m not the kind of lazy half-wit to discuss something without actually reading it, no doubt this probably isn’t the first that you’re hearing about it. In that span of time, I’ve heard some of the complaints made of it, as well as reading it for myself.
 
What I found in the paper is this, that they presented a balanced and nuanced representation of the subject matter covered, at a quality easily within the top 5% of papers I come across. There are no “hot takes”, nothing spicy, this is just “bread and butter” research, replicable down to the “Spectra 360 salt- and chloride-free electrode gel” they used for EEG connections. 
 
The EEG data is also VERY clear, showing MAJOR declines in connectivity and activity across brainwave bands, particularly those closely associated with “System 2” thinking. Yes, lower brain activity across the board, and lower activity indicative of critical thinking, is what LLM-dependent users offer. The severe decline in such higher order thinking also creates a severe decline in any value such an individual can offer to any business process. 

No domain experts should find any of this surprising, though their domain would need to cover cognitive bias, not just AI. Dunning-Kruger-curve-fitting effects are also evident in the study’s groups, such as the LLM group being 94% satisfied, while precisely none of them could provide a single correct quote from their own essay (S1). Satisfaction ran parallel to the brain-only group, but their performance did not.

It is also entirely predictable that this cognitive atrophy from people who may now very literally be called “LLM-brained” will grow progressively worse over time, as they offload more of their own cognition to faux-cognitive systems like LLMs and their absurdly anthropomorphized derivatives (“agents”). The progressive decline in “System 2” thinking also makes them more dependent/atrophied/addicted over time, like alcoholics or drug addicts.

That is what these tech companies are pushing on you, your business, and your children. Personally, I look forward to a follow-up study comparing LLM users directly to people who’re drunk or high at the time of testing. Remember, this study was pretty short-term, 4 sessions, so it may well get much worse with time.
 
This post is massively abridged, as it is a 200-page paper, and even my first draft of a post for it ran >700 characters over. They were thorough, and anyone who hasn’t read it should sooner step in front of oncoming traffic than critique actual researchers. I’ll gladly give you a push in the right direction should that be required.