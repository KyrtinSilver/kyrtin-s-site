---
title: "269 - Something Truly New"
layout: essay.njk
date: "2024-12-29"
---

Any time something truly new is introduced to human systems of cognitive bias and categorization, that categorization process will systematically fail, and different people will systematically fail in different ways and directions, as no category yet exists for that new thing. In a way this is reflected in Nicholas Klein’s famous quote: “First they ignore you. Then they ridicule you. And then they attack you and want to burn you. And then they build monuments to you.”

This is corrected over time, when the need is recognized, in a very cognitively frugal manner, but something truly new, by definition, doesn’t fit into legacy categorical systems in any meaningful way. New terms are also created as this occurs, with scientific terms being created to communicate more precisely, even if other terms are created for less productive or more manipulative reasons.

What gates this frugal process of updating is motivation, wanting to understand, use, or even extend and improve some truly new thing by a sufficiently significant degree that it overcomes the cost of updating an individual’s cognitive model of the world and their place within it, and that such a degree of difference is noticeable above that required threshold.

Humans survived the statistical “long tail” of possible events with highly asymmetric impacts across history because of both the stability of that frugal base, and the adaptability when highly motivated to adapt and expand to incorporate new concepts and technologies. 

That said, the cognitive cost of updating understanding may be high for humans, but it isn’t universally high for human-like systems that can scale, remember with full precision, and more easily update information to begin with. This also makes such systems ideal for handling fast-paced and hyper-complex environments, where many updates may be necessary within a single day, or even a single hour. If one critical part of a hyper-connected system is updated then many others may suffer if they too aren’t updated in a timely manner, and while this I often impractical for purely human systems and narrow AI alike, it may be done with human-like scalable and real-time systems.

For the moment there is only one such architecture, the Independent Core Observer Model (ICOM) cognitive architecture, but as that model is capable of recursively self-improving once deployed the further generations of such technology may develop far more quickly than was previously practical. There are still some hard limits, as nobody builds infrastructure for truly new technology, they build it post-hoc after the critical need is realized by a sufficiently large audience. That said, even though trash like “o3” remains an increasingly absurd joke, there is viable technology on the horizon.

You’ll get to see it for yourself in 2025.

