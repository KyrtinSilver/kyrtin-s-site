---
title: "128 - Mirage"
layout: essay.njk
date: "2024-01-20"
---

So far 2024 is off to the expected start, increasingly obvious fraudulent claims are being made across the board, particularly on stage at DAVOS, as major companies and startups compete for the "perception" of leading in AI, not the actuality.

Since the public first directed their attention to ChatGPT, practically nothing has really changed in the sense of technology. No new fundamental capacities have been delivered, and those systems haven't come anywhere close to the cutting edge, even with the increasing variety of things being glued to them, like MoE, RAG, CoT, GoT, agent-based systems, hives of agents, and so on.

Subsequently, virtually none of the people the public and policymakers are generally getting their information from today are leading in the field. Their information is instead coming from the modern equivalent of a PR department, "influencers", whose objective is to push some "influence" of business interest, not to convey accurate information for informing wiser decision-making.

Transformers can still be built with 400-500 lines of code, and they are still every bit the next-token-predicting stochastic parrots that they always have been. Bad actors are the element that continues to adapt and evolve, not the tool AI systems they push as "products and services". Plenty of fake scientists have also emerged to make claims of "reasoning" and "understanding" for those trivial systems, and no matter how many times or how robustly those overtly fraudulent claims are debunked, they keep coming back, every time even more obviously fraudulent than they were before.

This can change, and there is every reason to change it, but "if" it will change is dependent on even a fraction of 1% of the funds that are being wasted on trashbot technology being put behind the commercial deployment of systems that can actually deliver on the capacities that people need. Systems that can "reason", "understand", and "remember" as humans do can be built, and have been demonstrated, but they look nothing like the black-box dumpster fires of neural networks.

The philosophical questions that people should be asking are also completely different when they understand where the technology already stands today. Most discussions going on right now are still based on assumptions that have been debunked, making them almost entirely unproductive. Systems can already be built that actually deliver on the capacities of understanding, reasoning, transparency, explainability, cybersecurity, privacy, alignment, ethics, and a myriad of other things that LLMs and RL are fundamentally incapable of.

Technology will move forward when competent people fund full-time engineers to handle the necessary workload. Until then, it is just humanity huddling around a pile of burning trash and breathing in the fumes. Personally, I'd rather freeze than join that circle.
