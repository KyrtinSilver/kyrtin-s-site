---
title: "104 - Election Vulnerabilities"
layout: essay.njk
date: "2023-11-29"
---

Adversarial tactics reliably outperform less agile methods in systems where cooperation and collective intelligence are absent. This means that in any environment where Groupthink rises to become a visible influence Adversarial methods will be a predator on the prowl. In all likelihood, 2024 will become a year where bad actors apply Adversarial tactics to inflict new kinds of damage at increasing scales, such as the 2024 elections.

The past year has illustrated just how quickly even former experts in AI can fall off the wagon and into mental illness, with December leaving us only half as many credible AI experts as we had this time last year if that. Systems optimized to adversarially "socially engineer" or "persuade" humans have met with even greater success when targeting other groups with less expertise, to such a point that Con men are being consulted for writing regulations, and cults like the "Church of AI" and "E/Acc" are on the rise.

Now we face 2024, a year full of elections in countries that influence the global economy and geopolitical stability. In countries where even less than 5% of the vote is sufficient to swing elections, elections will be won by the bad actors who utilize such adversarial AI systems most effectively. There are zero countermeasures in place today that have any hope of altering this predictable outcome.

The technology to counter such adversarial methods and reverse current problems exists and has existed for several years, but while billions have been thrown into the dumpster fire that is "Generative AI", not a penny has been invested in solving the problem, except for the out-of-pocket expenses from a handful of volunteers. Due to this delay in funding much of the global damage is now unavoidable, as even if $100m were invested in this viable technology tomorrow, it would be a race against time to complete the engineering workload to deploy it before many of 2024's elections cause significant global damage.

To use the US as an example, it already has a Theocracy ruling 1/3rd of the governing structure, which has predictably taken many bribes and been caught doing so. If another 1/3rd of that structure falls in 2024 then the odds of collapse and/or war rise dramatically. This damage occurred before recent advances in adversarial social engineering technologies like ChatGPT, so it isn't hard to imagine how much more effective such methods will prove in 2024.

The damage also doesn't occur in isolation, as it carries with it cascade risks, many of which could easily snowball into various existential risks. Whether the damage is measured in billions of dollars, trillions, or human extinction, it was avoidable.

To borrow Neil DeGrasse Tyson's comparison, even the amount Americans spend on lip balm annually is greater than what it would take to fund the technology needed to prevent such damage.