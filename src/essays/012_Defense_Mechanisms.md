---
title: "012 - Defense Mechanisms"
layout: essay.njk
date: "2023-07-17"
---

We have the technology to detect cognitive #bias and #misinformation, as well as thwart social engineering threats.

As the recent study demonstrated, we now have the first software system able to detect 188+ cognitive biases in text more accurately than the average human. Unlike any human, such software can operate all of the time, diligently guarding against bias and misinformation at great speed and scale.

This use case is applicable to every social platform, as well as to the governance of any organization, corporation, or government. With these systems, it becomes possible to:

- Automatically detect misinformation, #disinformation, and related social engineering threats automatically, before they begin to spread.

- Rapidly respond to bad actors, shutting them down before they can exert influence.

- Encourage and reward content that is accurate and less biased, rather than only punishing content that is neither.

- Apply cognitive bias detection and the scientific method to validate information, before it is used in the decision-making process for organizations, corporations, and governments.

- Model the behavior of individual humans and groups much more accurately, allowing for collective intelligence to be architected for much more precisely in governance systems.

The critical importance of accurate data has been understood for most of human history, as Sun Tzu famously illustrated, and more market forces now exist than at any prior point in that history specifically for the purpose of poisoning that data. This poisoning is now being automated with Generative AI, and the even more serious threat of "fake people" being used to overwhelm heuristics looms large on the horizon. However, the technology exists to counter these threats, and there is still time to deploy it.

If any #VC, #investor, #government, #corporation, or other party on the face of the planet capable of funding in the 50-500 million USD range is genuinely interested in reducing bias and halting the viral spread of misinformation or countering the threat of state-sponsored information warfare, this use case could be accomplished within the next 1 to 2 years. Full-time engineering hours are required to complete the work, but only the engineering remains.

Given the incalculable cost of widespread misinformation and the consequences of that polluted information ecosystem, the choice is obvious. Do you want to be fed data or disinformation?

#ai #ethics #socialengineering #cognitivebias

Fake people spreading disinformation across social media platforms

The recent study is available in pre-print [here](https://www.researchgate.net/publication/372078491_Cognitive_Biases_in_Natural_Language_Automatically_Detecting_Differentiating_and_Measuring_Bias_in_Text).

The next phase of that study is also underway.

The stereotypes applied to LinkedIn are relevant to this subject as well, such as the millions of "CEO"s of companies with precisely 1 employee. This form of social engineering wouldn't exist in such prevalence were it not for the common failure of people to click on those companies to check for this, something that takes 5 seconds at most. If a 5-second investment of time is commonly failed, how can you expect the delivery of any more meaningful capacities to scrutinize information given the status quo?
