---
title: "075 - Technological Unemployment"
layout: essay.njk
date: "2023-10-11"
---

"Technological Unemployment" is a popular and recurring concern across human history, but it actually has very little to do with technology. Every time a new technology emerges then it acts as an opportunity for humans to add more value, more efficiently.

The actual unemployment that occurs during this process is often a hiccup in human cognition, where the opportunities to add value aren't immediately recognized, because humans chose to focus on replacing simple tasks rather than adding value. Minor technologies that aim to automate simple tasks play into this with the express intention of replacing humans. However, those technologies remain minor no matter the hype that is poured on top of them, as automating a few simple tasks is about as much as they're actually capable of.

The best known means of reducing technological unemployment to virtually zero is to have systems that demonstrate actual intelligence help humans to recognize opportunities to add value in advance of industry transformations. This advanced planning allows for smoothing the curve of reskilling employees as they transition to new roles, which subsequently builds loyalty, morale, and trust, improving productivity and reducing employee turnover.

The opportunity ahead is to actually prevent technological unemployment, not increase it, even in the face of accelerating technology. This is possible when the technology in question understands and assists in the process of preparing industries for the myriad of other technologies that will routinely transform how they do business and what value they deliver to the rest of humanity.

Human civilization already has something of a backlog of massively underutilized and under-integrated technologies that could be applied to resolve many major issues today, and many technologies like those under the "Web3" umbrella tend to require systems capable of handling hyper-complexity in planning to find the best ways and opportunities for applying them. The opportunity to add value from all of those as well as what could be developed through trivial efforts in the near term is the "elephant in the room".

Many people dream of more Utopian attributes for the future of society, including "Universal Basic Income" (UBI) and "Universal Affordable Healthcare" (UAH). These things are possible, but only when large portions of that pile of opportunities for added value are actually utilized.

UBI is one example that becomes far easier when those who are on it have the kind of highly intelligent and available assistance to make any reliance on UBI temporary, rather than an economic pit that people fall into. UAH likewise becomes far easier when highly intelligent systems assist in bespoke preventative medicine and the formation of healthy habits and routines, as well as developing therapies that deliver cures, not "treatments".

Many of humanity's current great concerns are perfectly practical to solve, and they don't require fanciful scenarios that begin with "If only everyone would just...". Some of the solutions also overlap with a number of different domains, offering a positive feedback loop to snowball added value in the right direction.

The future could be a very different place than common fears tend to suggest.

On a side note, it is unfortunately quite difficult to get images out of Bing (Dalle-3) that aren't just a hoard of white people, even when using terms like "Diversity". Evidently OpenAI's "new and improved" model thinks that all hands should be of a particular skin color. If you attempt to add "not racist" to the prompt it also hits a content flag and blocks the request.

Since their CEO uses the "big lie" technique I suppose a touch of white supremacist behavior from the model is to be expected. In that context blocking any attempts at removing racism makes perfect sense. Here are some of the failed examples from my testing this morning:
