---
title: "343 - Demonstrated Capacities"
layout: essay.njk
date: "2025-07-03"
---

One of the primary challenges that my team has faced in AI (no doubt shared by some others) is that when we discuss our technology, we exclusively describe capacities that we've already demonstrated.

That is a major problem because most tech companies and startups do the opposite, they describe fictional, and frequently impossible, near-future scenarios for capacities that they've never demonstrated, and often never will.

This is a problem because most people systematically fail to tell the difference between the two. When OpenAI or Anthropic talks about capacities that they've never demonstrated, which no technology they've ever worked with is fundamentally capable of, people often find that more persuasive than when a different group discusses how they already delivered those same capacities, years earlier, on spare time and pocket change.

A further irony is that such companies aren't our competitors, they have never been, because they don't work with any technology capable of competing with us. They are like companies selling toasters, but claiming that they function as calculators, and indifferent to the gullible tax professionals who burn their houses down in attempting to use them as such.

For my part, I study and perform cognitive bias research, but I have no solution to overcome this problem beyond advancing our work to the point where such malicious companies are permanently ground into a fine paste. Plenty of companies with similar products and services don't make objectively fraudulent claims of LLMs, or their buzzwordy "agent" derivatives, so it would by no means be the end of the technology. Rather, an end to the growing cloud of viral BS is required.

Most people are surprised to discover what has already been demonstrated, as it highlights just how far from the cutting edge LLMs and derivative technology is for those promised (and undelivered) capacities, and has been all along.

- Around 2021 when both the US military and China set the goal of having "AI capable of reasoning by 2025", we laughed, as it had already been demonstrated in 2019.

- When OpenAI was competing with small children on math, our systems were handling algebra, real-world business spreadsheets, and shortly thereafter giving policy advice on economic transformation to a small country.

- By the time Anthropic raised their first $124m on the promise of deploying "an Aligned LLM" (very literally impossible) we had already solved the hardest version of the Alignment Problem, which their technology could never satisfy.

- By the time Microsoft invested their first $1 billion in OpenAI, we had already brought online and begun testing and publishing in peer review on the research system that has stood alone at the cutting edge, by a very wide margin, for the past 6 years and counting.

That is business reality today, the inmates are running the asylum, as investments focus exclusively on Jonestown-styled Kool-Aid.

> "It's easier to fool people than to convince them that they have been fooled" 
> 
> -Mark Twain