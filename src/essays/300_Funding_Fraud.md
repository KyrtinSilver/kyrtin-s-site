---
title: "300 - Funding Fraud"
layout: essay.njk
date: "2025-03-27"
---

This morning as I was combing through the financial data on AI startups to update my comparisons for 2025, with new companies and updated valuations and raises, it struck me that the influence of overt fraud on increasing funds raised has continued to climb since last year.

For the revised numbers the 3 "AI Startups" (OpenAI, Anthropic, and SSI) guilty of varying degrees of known and demonstrable fraud had valuations over 2 times higher and raised just over 15 times more funding than the 3 AI startups (DeepSeek, Scale AI, and Perplexity) without any instances of fraud that I've come across thus far. This was even with assuming the most conservative figures for comparison, giving DeepSeek the high end of their estimated valuation, as well as the $1bn+ in known assets, which though they aren't a formal investment are assumed to be at the company's disposal.

It has been known for some years that misinformation and disinformation spread 6 times further and faster than real data, but this 15-fold multiplier on funding secured, up from 5-fold last year, is quite troubling. This means that the known problem of dead-end technology like LLMs and RL "sucking the oxygen out of the room" is still increasing in severity. Without minimum-viable investments in technology that can actually deliver the capacities that are hyped up and unfulfilled today, humanity will likely continue to accelerate on a steep downward trajectory over the next couple of years, before plowing into rock bottom at critical velocity, with countless cascade risks.

In late 2022's edition of this comparison, Anthropic was the poster child for a terrible investment, even before it was revealed that 71% of their funds raised at that time came from Sam Bankman-Fried's money laundering. Today they've been eclipsed by the new posterchild for a terrible investment, Ilya Sutskever's "Safe Superintelligence" (SSI), whose operations are eerily reminiscent of Theranos.

I highly recommend [Daniel Kahneman's method of joint comparison](https://faculty.sites.iastate.edu/tesfatsi/archive/tesfatsi/JudgementAndChoice.MappingBoundedRationality.DKahneman2003.pdf), for purposes of reducing cognitive bias when comparing similar companies, candidates, etc. If more people funding companies were less biased then these numbers wouldn't be so abysmal. Ironically, this makes the most biased investors first on the chopping block for more fundamentally capable AI.

