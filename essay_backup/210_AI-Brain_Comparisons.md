---
title: "210 - AI-Brain Comparisons"
layout: essay.njk
date: "2024-06-12"
---

A common scenario in the AI domain:

Researcher #1: "Common AI models like LLMs go about (X) by doing (Y)."

Na√Øve Tech Bro: "Just like humans do!"

[...Researchers #1-10 all glare at the tech bro with deep contempt...]

This common scenario is one of the more clear-cut examples of Confirmation Bias, one of the best-known cognitive biases, where an individual "wants" something to be true, and so they seek out confirmatory "evidence" or opinions, even if 99% of all context clearly shows that something is demonstrably false.

This also relates to the human tendency to construct and favor plausible-sounding, but wrong, narratives and material that serves to support those narratives, with indifference to the truth. This is one of the only things that humans and LLMs may be vaguely similar on, performance on the task of "Bullshit" generation, as defined by Frankfurt (2005). Of course, the process under the hood even in this case is nothing remotely similar between the two.

Worse yet, notorious frauds like Geoffrey Hinton, a so-called "Godfather of AI", are known for repeating such demonstrably false comparisons between neural networks and the human brain like clockwork. Throw a stone in a room full of neuroscientists and everyone it hits is likely to have an extensive rant on the subject of why neural networks are nothing remotely like the human brain, and indeed most of the AI domain's demonstrably false comparisons are built on top of 1970s (or earlier) theories about the brain, long-debunked.

Substitution Bias is another lesser-known and much broader class of cognitive biases, which unfortunately leads people to mistake a high "prestige" fraud like Hinton for a credible source of information, including the absurd "Godfather of AI" title. For those unfamiliar, Substitution Biases attempt to substitute the answer to one question by answering a completely different one, often unrelated, and much easier to answer, such as trying to answer the question of "Is Hinton actually credible?" by answering the much easier question of "What is Hinton's H-index score?" or "How do I feel about what Hinton says?".

AI "Benchmarks" are another common example of Substitution Biases, as they're known to be virtually worthless, excluding the moment that such benchmarks first appear (if they're done well). The only potential exception is Chollet's ARC challenge, which has successfully withstood the industry's best attempts to game the benchmark over several years.

Of course, the virtual worthlessness of all other benchmarks doesn't stop AI's "faux-experts" from constantly citing them, as benchmarks offer an easy mechanism for the social engineering of wealthy suckers at scale.