---
title: "317 - Human Constraints"
layout: essay.njk
date: "2025-03-19"
---

The hardest version of the "Alignment Problem" has been solved since 2022. How to build AGI has been minimally solved since 2019, and more comprehensively solved in 2021, with only the engineering workload remaining. The real problems that remain are matters such as educating large post-indoctrination populations about the reality that they've been systematically conned, year after year, farmed for attention with fearmongering and delusional utopian promises built on faulty premises.

There is also the closely related problem of minimum thresholds, such as the minimum viable levels of funding required to hire veteran full-time 10x engineers to cover the workload, people who tend to have mortgages and families that prevent them from operating on savings and ramen. 

More than 95% of the people able to fund those minimum thresholds have the attention spans of fruit flies and a subsequently cognitive-bias-dominated decision-making process, which means that when they're wrong they're systematically wrong. As cognitive biases quickly go off the rails when applied to any truly new technology, this makes the overwhelming majority of investors systematically wrong in such cases, less accurate than a literal random number generator.

The genuinely hard problems tend to focus on humans operating out of their depth, spread too thin, while being systematically misled, the irony being that they self-sabotage by ignoring the very technology required to overcome those challenges. Technology is comparatively easy because just as a coding language follows formal constraints and processes, technology is fundamentally bounded by reality. Human cognition is influenced by, but not really constrained by reality, short of death. People can and do choose to believe things that are demonstrably false, and even mutually exclusive, aka cognitive dissonance, and that produces much harder problems than the technology itself.

Claims that "AGI is just around the corner" and that "AGI is impossible" are equally laughable, as both demonstrate the same core failure, originating from individuals who, willfully or not, remain oblivious of reality. Attempts to "move the goalpost" and redefine the term are generally indicative of bad actors, being diametrically opposed to research, as researchers are specifically taught to use precise language in scientific communication.

Without understanding the reality of which problems remain solved and unsolved, no viable predictions can be made, and so many broken clocks may be right twice per day, but that isn't to be confused with an accurate reflection of time in reality.

![Human Constraints](https://media.licdn.com/dms/image/v2/D5622AQGgAnKBZCMAVw/feedshare-shrink_800/B56ZWX6i.bGUAg-/0/1742010462702?e=1745452800&v=beta&t=V3X-38w_XbDMPoQYfW-pHB6BX5MjUg9Oem7HyQWaST4)